{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# 16.0简介",
   "id": "cc51cb73fd7114b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "核心知识点\n",
    "- 逻辑回归（Logistic Regression）虽名为 “回归”，但本质是有监督分类方法，用于预测观察值属于某一类别的概率。\n",
    "- 可扩展为多元逻辑回归（Multinomial Logistic Regression），处理多分类问题。\n",
    "- 核心优势：输出概率值，可解释性强，计算效率高，是工业界最常用的分类算法之一。\n",
    "- 本章重点：使用 scikit-learn 训练、调优和评估各类逻辑回归分类器。"
   ],
   "id": "cbeccb09aa4ff211"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 16.1 训练二元分类器",
   "id": "cc7b7c1933e1721e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "问题描述\n",
    "- 训练一个简单的二元分类器，将观察值分为两个类别。"
   ],
   "id": "7f22f671626c191f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:28:32.428574Z",
     "start_time": "2026-02-10T08:28:29.998180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from notebooks.Chapter15_KNN.ch15_KNN import new_observation\n",
    "\n",
    "# 加载仅有两个分类的数据\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data[:100,:]\n",
    "target = iris.target[:100]\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 创建一个逻辑回归对象\n",
    "logistic_regression = LogisticRegression(random_state=0)\n",
    "\n",
    "# 训练模型\n",
    "model = logistic_regression.fit(features_standardized, target)"
   ],
   "id": "75bf8dc148adff38",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:29:20.182725Z",
     "start_time": "2026-02-10T08:29:20.157191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建一个观察值\n",
    "new_observation = [[.5,.5,.5,.5]]\n",
    "\n",
    "# 预测分类\n",
    "model.predict(new_observation)"
   ],
   "id": "8715b4a20a9f658d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:29:47.928771Z",
     "start_time": "2026-02-10T08:29:47.902890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看预测的概率\n",
    "model.predict_proba(new_observation)"
   ],
   "id": "9c7414a13eeb3e1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17740549, 0.82259451]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 核心知识点\n",
    "\n",
    "1.  **二元分类本质**：逻辑回归是二元分类器，目标向量仅能取两个值（0或1）。\n",
    "\n",
    "2.  **核心公式（Sigmoid 函数）**：\n",
    "    $$\n",
    "    P(y_i = 1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_i)}}\n",
    "    $$\n",
    "    - $P(y_i = 1 | X)$：第 $i$ 个观察值属于类别 1 的概率。\n",
    "    - $\\beta_0, \\beta_1$：模型需要学习的参数。\n",
    "    - 输出值被限制在 $[0, 1]$ 之间，若 $P > 0.5$，则预测为类别 1，否则为类别 0。\n",
    "\n",
    "3.  **预测方法**：\n",
    "    - `predict()`：直接输出预测类别。\n",
    "    - `predict_proba()`：输出样本属于每个类别的概率，可用于评估预测置信度。"
   ],
   "id": "e3177aaa1f1fa6eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 16.2 训练多元分类器",
   "id": "c93500b2b965d7db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "问题描述\n",
    "处理包含多个类别的数据集，训练多分类器。"
   ],
   "id": "4753c201a1c507d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:52:43.993498Z",
     "start_time": "2026-02-10T08:52:43.320267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载数据\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 创建一对多的逻辑回归对象\n",
    "logistic_regression = LogisticRegression(random_state=0,multi_class='ovr')\n",
    "\n",
    "# 训练模型\n",
    "model = logistic_regression.fit(features_standardized, target)"
   ],
   "id": "2909ef228d030720",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 核心知识点\n",
    "\n",
    "## 1. 一对多（One-vs-Rest, OVR）\n",
    "\n",
    "### 工作原理\n",
    "- 对每个类别训练一个独立的二元分类器，判断观察值是否属于该类别。\n",
    "- 假设各类别问题相互独立，实现简单，但概率校准性较差。\n",
    "\n",
    "### 特点\n",
    "| 优点 | 缺点 |\n",
    "|------|------|\n",
    "| 实现简单，计算效率高 | 类别间独立性假设可能不成立 |\n",
    "| 可并行训练多个分类器 | 概率校准性较差 |\n",
    "| 适用于大规模数据 | 可能产生不一致的预测结果 |\n",
    "\n",
    "## 2. 多元逻辑回归（Multinomial Logistic Regression, MLR）\n",
    "\n",
    "### Softmax函数公式\n",
    "$$\n",
    "P(y_i = k | X) = \\frac{e^{a_k^T x_i}}{\\sum_{j=1}^K e^{a_j^T x_i}}\n",
    "$$\n",
    "\n",
    "### 参数说明\n",
    "\n",
    "| 符号 | 含义 | 说明 |\n",
    "|------|------|------|\n",
    "| $K$ | 类别总数 | 多分类的类别数量 |\n",
    "| $a_k^T x_i$ | 线性组合 | 第k个类别的决策函数 |\n",
    "| $P(y_i = k | X)$ | 条件概率 | 样本属于第k个类别的概率 |\n",
    "\n",
    "### 核心特点\n",
    "- **直接输出**：同时输出样本属于每个类别的概率\n",
    "- **概率校准**：概率值经过更好的校准，预测更可靠\n",
    "- **归一化**：所有类别概率之和为1\n",
    "\n",
    "## 3. 参数选择\n",
    "\n",
    "### 两种策略对比\n",
    "\n",
    "| 策略 | 参数设置 | 适用场景 | 特点 |\n",
    "|------|----------|----------|------|\n",
    "| OVR | `multi_class=\"ovr\"` | 1. 类别较少时<br>2. 计算资源有限<br>3. 需要快速实验时 | 1. 训练K个独立分类器<br>2. 概率未归一化<br>3. 默认设置 |\n",
    "| MLR | `multi_class=\"multinomial\"` | 1. 类别较多时<br>2. 需要准确的概率估计<br>3. 类别间互斥时 | 1. 单一模型处理多分类<br>2. 概率归一化<br>3. 理论更完备 |\n",
    "\n"
   ],
   "id": "5a0c924e4f64b1cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 16.3 通过正则化来减小方差",
   "id": "8251cd6630b2c919"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T12:40:48.539541Z",
     "start_time": "2026-02-10T12:40:43.473337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载数据\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 创建一个决策树分类器对象\n",
    "logistic_regression = LogisticRegressionCV(penalty='l2',Cs= 10,random_state=0,n_jobs=-1)\n",
    "\n",
    "# 训练模型\n",
    "model = logistic_regression.fit(features_standardized, target)"
   ],
   "id": "82939120c4f8775a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 核心知识点\n",
    "\n",
    "1.  **正则化原理**：通过在损失函数中添加惩罚项，惩罚复杂模型，减小方差。\n",
    "    - **L1 惩罚**：$\\alpha \\sum_{j=1}^p |\\hat{\\beta}_j|$，可产生稀疏解（部分参数为 0，实现特征选择）。\n",
    "    - **L2 惩罚**：$\\alpha \\sum_{j=1}^p \\hat{\\beta}_j^2$，惩罚大参数值，防止过拟合。\n",
    "\n",
    "2.  **scikit-learn 中的实现**：\n",
    "    - 使用参数 `C` 代替 $\\alpha$，其中 $C = \\frac{1}{\\alpha}$。\n",
    "    - $C$ 越大，正则化强度越弱；$C$ 越小，正则化强度越强。\n",
    "\n",
    "3.  **自动调优**：`LogisticRegressionCV` 可通过交叉验证自动搜索最优的 $C$ 值，`cs` 参数指定搜索范围或数量。"
   ],
   "id": "b53eb78f79736ad2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 16.4 在超大数据集上训练分类器",
   "id": "2b52e05d67e64058"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T12:54:19.312765Z",
     "start_time": "2026-02-10T12:54:19.275311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载数据\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 创建逻辑回归对象\n",
    "logistic_regression = LogisticRegression(random_state=0,solver = 'sag')\n",
    "\n",
    "# 训练模型\n",
    "model = logistic_regression.fit(features_standardized, target)"
   ],
   "id": "b711d057a84f0c0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 核心知识点\n",
    "1.  求解器（solver）：scikit-learn 提供多种训练逻辑回归的算法，solver参数用于指定。\n",
    "2.  随机平均梯度（Stochastic Average Gradient, SAG）：\n",
    "    - 适合超大数据集，训练速度显著快于传统梯度下降。\n",
    "    - 对特征尺度非常敏感，必须先对特征进行标准化。\n",
    "3.  其他求解器：liblinear（适合小数据集、二元分类）、newton-cg、lbfgs（适合多分类）等，scikit-learn 会根据场景自动推荐。"
   ],
   "id": "d57961c1975232e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T13:00:53.211653Z",
     "start_time": "2026-02-10T13:00:53.200094Z"
    }
   },
   "cell_type": "markdown",
   "source": "# 16.5 处理不均衡的分类",
   "id": "ebad324c310afd45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "问题描述：\n",
    "在类别分布严重不均衡的数据集上训练分类器，避免模型偏向多数类。"
   ],
   "id": "ec8e6b2967dcb942"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T13:06:42.947251Z",
     "start_time": "2026-02-10T13:06:42.923395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载数据\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 移除前40个观察值，使分类严重不均衡\n",
    "features = features[40:,:]\n",
    "target = target[40:]\n",
    "\n",
    "# 创建目标向量，0代表分类为0,1代表除分数0以外的其他的分类\n",
    "target = np.where((target==0),0,1)\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# 创建决策树分类器对象\n",
    "logistic_regression = LogisticRegression(random_state=0,class_weight='balanced')\n",
    "\n",
    "# 训练模型\n",
    "model = logistic_regression.fit(features_standardized, target)"
   ],
   "id": "f039394b0f61b711",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 核心知识点\n",
    "\n",
    "1.  **不均衡分类的影响**：模型会倾向于预测多数类，导致稀有类的预测性能很差。\n",
    "\n",
    "2.  **自动权重调整**：`class_weight=\"balanced\"` 会根据类别频率自动计算权重：\n",
    "    $$\n",
    "    w_j = \\frac{n}{k n_j}\n",
    "    $$\n",
    "    - $w_j$：类别j的权重。\n",
    "    - $n$：总样本数。\n",
    "    - $n_j$：类别j的样本数。\n",
    "    - $k$：类别总数。\n",
    "\n",
    "3.  **效果**：增大稀有类的权重，减小多数类的权重，使模型在训练时更关注稀有类，纠正数据不均衡问题。"
   ],
   "id": "a2334bbfa06ff86c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 第16章 逻辑回归·精简总结\n",
    "逻辑回归**名为回归、实为分类算法**，核心是预测样本属于某一类别的概率，具备可解释性强、计算高效、适配工业场景的特点，是最常用的分类模型之一，本章围绕其训练、调优、适配场景展开：\n",
    "\n",
    "1. **二元分类（基础场景）**\n",
    "    仅处理二分类任务，通过**Sigmoid函数**将线性结果映射到0~1之间，以0.5为分类阈值；训练前必须对特征做标准化，模型支持`predict()`直接输出类别、`predict_proba()`输出分类概率，方便判断预测置信度。\n",
    "\n",
    "2. **多分类扩展**\n",
    "    支持两种多分类模式：\n",
    "    - 一对多（OVR）：为每个类别单独训练二元分类器，实现简单；\n",
    "    - 多元逻辑回归：通过**Softmax函数**直接输出多类别概率，概率校准更精准，通过`multi_class`参数切换两种模式。\n",
    "\n",
    "3. **正则化防过拟合**\n",
    "    用L1、L2正则化约束模型复杂度，降低过拟合风险：L1可生成稀疏参数实现特征选择，L2更常用、能缩小参数值；scikit-learn中用参数`C`控制正则强度（`C=1/α`，C越小、正则越强），可通过`LogisticRegressionCV`结合交叉验证自动优选最优`C`值。\n",
    "\n",
    "4. **超大数据集优化**\n",
    "    大数据场景下选用**SAG随机平均梯度求解器**，训练速度远快于传统算法；但SAG对特征尺度极度敏感，**必须先做特征标准化**才能保证效果。\n",
    "\n",
    "5. **不均衡数据处理**\n",
    "    针对类别样本数量悬殊的场景，设置`class_weight='balanced'`，模型会自动根据样本数量为稀有类别分配更高权重，避免模型偏向多数类，提升稀有类别的预测效果。"
   ],
   "id": "22324b433f876842"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f72d2ba18fc6acc5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
