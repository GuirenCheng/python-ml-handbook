{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# 6.0简介",
   "id": "55df2a6900bb93ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "知识点：文本数据预处理是自然语言处理和文本分析的重要步骤，包括清洗、分词、移除停用词、提取词干、向量化等操作。",
   "id": "aebb4e1865609521"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.1 清洗文本",
   "id": "334250e86da20877"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：对非结构化的文本数据进行基本清洗。",
   "id": "9873bb88561d7062"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "去掉首尾两端的空格：",
   "id": "6b7fffa8a33c6e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T04:45:38.581894Z",
     "start_time": "2026-01-30T04:45:38.569661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建文本\n",
    "text_data = [\"  Interrobang. By Aishwarya Henriette  \",\n",
    "             \"Parking And Going. By Karl Gautier   \",\n",
    "             \"  Today Is The night. By Jarek Prakash  \"]\n",
    "\n",
    "# 去除文本两端的空格\n",
    "strip_whitespace = [string.strip() for string in text_data]\n",
    "\n",
    "# 查看文本\n",
    "strip_whitespace\n",
    "# 输出:\n",
    "# ['Interrobang. By Aishwarya Henriette',\n",
    "#  'Parking And Going. By Karl Gautier',\n",
    "#  'Today Is The night. By Jarek Prakash']"
   ],
   "id": "31921b6a579393e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang. By Aishwarya Henriette',\n",
       " 'Parking And Going. By Karl Gautier',\n",
       " 'Today Is The night. By Jarek Prakash']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "删除句点：",
   "id": "6fbe8acbfe055bf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T04:46:02.758525Z",
     "start_time": "2026-01-30T04:46:02.749302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 删除句点\n",
    "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
    "\n",
    "# 查看文本\n",
    "remove_periods\n",
    "# 输出:\n",
    "# ['Interrobang By Aishwarya Henriette',\n",
    "#  'Parking And Going By Karl Gautier',\n",
    "#  'Today Is The night By Jarek Prakash']"
   ],
   "id": "db231b7936c99219",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang By Aishwarya Henriette',\n",
       " 'Parking And Going By Karl Gautier',\n",
       " 'Today Is The night By Jarek Prakash']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "自定义转换函数：",
   "id": "7b4e840a83565b67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T04:46:28.358398Z",
     "start_time": "2026-01-30T04:46:28.347369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建函数\n",
    "def capitalizer(string: str) -> str:\n",
    "    return string.upper()\n",
    "\n",
    "# 应用函数\n",
    "[capitalizer(string) for string in remove_periods]\n",
    "# 输出:\n",
    "# ['INTERROBANG BY AISHWARYA HENRIETTE',\n",
    "#  'PARKING AND GOING BY KARL GAUTIER',\n",
    "#  'TODAY IS THE NIGHT BY JAREK PRAKASH']"
   ],
   "id": "3f1f71bf8a32eded",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTERROBANG BY AISHWARYA HENRIETTE',\n",
       " 'PARKING AND GOING BY KARL GAUTIER',\n",
       " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "使用正则表达式：",
   "id": "fdd5e09c79ae3528"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T04:46:51.687513Z",
     "start_time": "2026-01-30T04:46:51.676806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "import re\n",
    "\n",
    "# 创建函数\n",
    "def replace_letters_with_X(string: str) -> str:\n",
    "    return re.sub(r\"[a-zA-Z]\", \"X\", string)\n",
    "\n",
    "# 应用函数\n",
    "[replace_letters_with_X(string) for string in remove_periods]\n",
    "# 输出:\n",
    "# ['XXXXXXXXXXXXXX X XXXXXXXXX XXXXXXXXX',\n",
    "#  'XXXXXXX XXX XXXXXXX X XXXX XXXXXX',\n",
    "#  'XXXXX XX XXX XXXXX X XXXXXX XXXXXX']"
   ],
   "id": "33d8fac00b2efc14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
       " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
       " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "讨论：大多数文本清洗操作可用Python字符串方法完成，复杂操作可用正则表达式。",
   "id": "89777be64d6fb628"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.2 解析并清洗HTML",
   "id": "cada7723092b1c1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：从HTML中提取并清洗文本。",
   "id": "aae91fe677e0bb2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T05:10:24.006010Z",
     "start_time": "2026-01-30T05:10:23.992991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 创建HTML代码\n",
    "html = \"\"\"\n",
    "<div class='full_name'><span style='font-weight:bold'>\n",
    "Masego Azra</span></div>\n",
    "\"\"\"\n",
    "\n",
    "# 解析HTML\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 查找class是\"full_name\"的div标签，并查看文本\n",
    "soup.find(\"div\", {\"class\": \"full_name\"}).text\n",
    "# 输出: 'Masego Azra'"
   ],
   "id": "5054d9478a9b2707",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMasego Azra'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "讨论：BeautifulSoup可方便地从HTML中提取文本内容，忽略标签。",
   "id": "84d7d6f7a133429c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.3 移除标点",
   "id": "5f1dd4f42801f98e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：移除文本数据中的标点符号。",
   "id": "23735de2ab15c935"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T05:12:36.362820Z",
     "start_time": "2026-01-30T05:12:36.103960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "# 创建文本\n",
    "text_data = ['Hi!!!! I. Love. This. Song..',\n",
    "             '10000% Agree!!!! #LoveIT',\n",
    "             'Right?!?']\n",
    "\n",
    "# 创建一个标点字典\n",
    "punctuation = dict.fromkeys(\n",
    "    i for i in range(sys.maxunicode)\n",
    "    if unicodedata.category(chr(i)).startswith(\"P\")\n",
    ")\n",
    "\n",
    "# 移除每个字符串中的标点\n",
    "[string.translate(punctuation) for string in text_data]\n",
    "# 输出:\n",
    "# ['Hi I Love This Song',\n",
    "#  '10000 Agree LoveIT',\n",
    "#  'Right']"
   ],
   "id": "8967f50f66c1507a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "讨论：使用unicodedata识别所有Unicode标点符号，通过translate批量移除",
   "id": "788e24a34af0143f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.4 文本分词",
   "id": "404ec5e4aceb1eee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：将文本分离成独立的单词。",
   "id": "c5ace6fbd18eef62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T05:56:52.754332Z",
     "start_time": "2026-01-30T05:56:52.705223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# 创建文本\n",
    "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
    "\n",
    "# 分词\n",
    "word_tokenize(string)\n",
    "# 输出:\n",
    "# ['The', 'science', 'of', 'today', 'is', 'the', 'technology',\n",
    "#  'of', 'tomorrow', '.', 'Tomorrow', 'is', 'today', '.']"
   ],
   "id": "5076aa013671bb52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'science',\n",
       " 'of',\n",
       " 'today',\n",
       " 'is',\n",
       " 'the',\n",
       " 'technology',\n",
       " 'of',\n",
       " 'tomorrow',\n",
       " '.',\n",
       " 'Tomorrow',\n",
       " 'is',\n",
       " 'today',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "切分为句子：",
   "id": "adc9e51083cc2fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T05:57:24.180964Z",
     "start_time": "2026-01-30T05:57:24.170264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# 切分成句子\n",
    "sent_tokenize(string)\n",
    "# 输出:\n",
    "# ['The science of today is the technology of tomorrow.',\n",
    "#  'Tomorrow is today.']"
   ],
   "id": "14f20be6dadc91e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "讨论：分词是文本预处理的关键步骤，将文本转换为可用于构建特征的单词序列。",
   "id": "a8f648d3c4a751a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.5 删除停止词",
   "id": "8ee6a7965735d8ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：删除文本中的常见停止词（如the, is, of）。",
   "id": "17e542f2a70ddbdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:03:48.713908Z",
     "start_time": "2026-01-30T06:03:48.694539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 创建单词序列\n",
    "tokenized_words = ['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', 'and', 'park']\n",
    "\n",
    "# 加载停止词\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# 删除停止词\n",
    "[word for word in tokenized_words if word not in stop_words]\n",
    "# 输出:\n",
    "# ['going', 'go', 'store', 'park']"
   ],
   "id": "e220086dc30bc586",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "讨论：\n",
    "停止词：对文本意义贡献很小的常见词（is, of, on等）\n",
    "删除停止词可减少特征维度，提高处理效率"
   ],
   "id": "fc1a21b7582d5984"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.6 提取词干",
   "id": "19951e3e01325f23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：将单词转换为其词根形式。",
   "id": "abe0810e7840b772"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:04:56.061228Z",
     "start_time": "2026-01-30T06:04:56.048586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# 创建单词序列\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "\n",
    "# 创建词干转换器\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# 应用词干转换器\n",
    "[porter.stem(word) for word in tokenized_words]\n",
    "# 输出:\n",
    "# ['i', 'am', 'humb', 'by', 'thi', 'tradit', 'meet']"
   ],
   "id": "f0d70089bdce7134",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "讨论：\n",
    "PorterStemmer：最流行的词干提取算法，通过移除单词后缀得到词根\n",
    "优点：将不同形式的单词统一（humbled, humbled → humb）\n",
    "缺点：可能产生非实际单词（traditional → tradit）"
   ],
   "id": "33463fc8687295ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.7标注词性",
   "id": "b89b78ecdb89f4eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：为文本中的每个单词标注词性。",
   "id": "581fe6c6450bfd5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:34:57.064699Z",
     "start_time": "2026-01-30T06:34:56.963990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# 创建文本\n",
    "text_data = \"Chris loved outdoor running\"\n",
    "\n",
    "# 使用预训练的词性标注器\n",
    "text_tagged = pos_tag(word_tokenize(text_data))\n",
    "\n",
    "# 查看词性\n",
    "text_tagged\n",
    "# 输出:\n",
    "# [('Chris', 'NNP'),\n",
    "#  ('loved', 'VBD'),\n",
    "#  ('outdoor', 'RP'),\n",
    "#  ('running', 'VBG')]"
   ],
   "id": "fdc4a815858c9570",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Penn Treebank词性标签示例：\n",
    "NNP：单数专有名词\n",
    "VBD：过去式动词\n",
    "VBG：动名词或现在分词\n",
    "JJ：形容词\n",
    "PRP：人称代词"
   ],
   "id": "f460c7401df154aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "按词性过滤：",
   "id": "73d02019a04d8944"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:36:26.898687Z",
     "start_time": "2026-01-30T06:36:26.887150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 过滤出名词\n",
    "noun_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "[word for word, tag in text_tagged if tag in noun_tags]\n",
    "# 输出: ['Chris']"
   ],
   "id": "85ac45b5c3c4f4d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chris']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "批量处理文档：",
   "id": "db3a05412eb74f31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:36:49.138402Z",
     "start_time": "2026-01-30T06:36:49.104817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建文本\n",
    "tweets = [\"I am eating a burrito for breakfast\",\n",
    "          \"Political science is an amazing field\",\n",
    "          \"San Francisco is an awesome city\"]\n",
    "\n",
    "# 创建列表\n",
    "tagged_tweets = []\n",
    "\n",
    "# 为每条推文中的每个单词加标签\n",
    "for tweet in tweets:\n",
    "    tweet_tag = pos_tag(word_tokenize(tweet))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])\n",
    "\n",
    "# 使用one-hot编码将标签转换成特征\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "one_hot_multi = MultiLabelBinarizer()\n",
    "\n",
    "one_hot_multi.fit_transform(tagged_tweets)\n",
    "# 输出词性标签的one-hot矩阵"
   ],
   "id": "1f50f05f8f566601",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.8将文本编制成词袋",
   "id": "1dcd93711af2d039"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：将文本转换为词频特征矩阵。",
   "id": "bfda4643ff0a4a88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:39:24.098834Z",
     "start_time": "2026-01-30T06:39:24.076620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 创建文本\n",
    "text_data = ['I love Brazil.Brazil!',\n",
    "             'Germany beats both',\n",
    "             'Sweden is best']\n",
    "\n",
    "# 创建词袋特征矩阵\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "# 查看稀疏矩阵\n",
    "bag_of_words\n",
    "# 输出: <3x8 sparse matrix ...>"
   ],
   "id": "f1f4ac479d09dbe3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "查看稠密矩阵：",
   "id": "cfa3f31f5b532062"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:40:26.180182Z",
     "start_time": "2026-01-30T06:40:26.170771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看词频矩阵\n",
    "bag_of_words.toarray()\n",
    "# 输出:\n",
    "# array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
    "#        [0, 1, 0, 0, 0, 1, 0, 1],\n",
    "#        [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
   ],
   "id": "4089d64b5160cff0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "查看特征名称：",
   "id": "bf31267f51716dc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:40:51.051144Z",
     "start_time": "2026-01-30T06:40:51.040634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看特征名（词汇表）\n",
    "count.get_feature_names_out()\n",
    "# 输出: array(['best', 'both', 'brazil', 'country', 'germany', 'is', 'sweden', 'the'], dtype=object)"
   ],
   "id": "10c421cb95fdd31f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love',\n",
       "       'sweden'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "限制词汇表：",
   "id": "7a1aea1846ca5fff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:41:11.162009Z",
     "start_time": "2026-01-30T06:41:11.150911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 只关注特定词汇\n",
    "count_brazil = CountVectorizer(vocabulary=['brazil'])\n",
    "bag = count_brazil.fit_transform(text_data)\n",
    "\n",
    "# 查看特征矩阵\n",
    "bag.toarray()\n",
    "# 输出:\n",
    "# array([[2],\n",
    "#        [0],\n",
    "#        [0]])"
   ],
   "id": "bb34909730c54bc9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "讨论：\n",
    "词袋模型：将文本转换为词频计数矩阵\n",
    "稀疏矩阵：默认输出，节省内存\n",
    "ngram_range：可设置提取N-gram特征\n",
    "vocabulary：可限制只关注特定词汇"
   ],
   "id": "489e2c06dd6ecef0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6.9按单词的重要性加权",
   "id": "64e2074beed8e84a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "问题描述：使用TF-IDF加权衡量单词在文档中的重要性。",
   "id": "f034fcfa0baf48f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:44:17.242779Z",
     "start_time": "2026-01-30T06:44:17.226461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载库\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 创建文本\n",
    "text_data = ['I love Brazil.Brazil!',\n",
    "             'Sweden is best',\n",
    "             'Germany beats both']\n",
    "\n",
    "# 创建TF-IDF特征矩阵\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# 查看TF-IDF特征矩阵\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "feature_matrix"
   ],
   "id": "fe111405abbf03f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "查看稠密矩阵：",
   "id": "5bf48a294d2a6846"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:44:18.728772Z",
     "start_time": "2026-01-30T06:44:18.708215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看TF-IDF特征矩阵的稠密矩阵形式\n",
    "feature_matrix.toarray()\n",
    "# 输出:\n",
    "# array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
    "#         0.        , 0.4472136 , 0.        ],\n",
    "#        [0.57735027, 0.57735027, 0.        , 0.        , 0.57735027,\n",
    "#         0.        , 0.        , 0.        ],\n",
    "#        [0.57735027, 0.        , 0.57735027, 0.        , 0.        ,\n",
    "#         0.57735027, 0.        , 0.        ]])"
   ],
   "id": "f01a1d9a7e19c26a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "查看词汇表：",
   "id": "12ba8852f48f1a2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T06:46:13.501172Z",
     "start_time": "2026-01-30T06:46:13.490414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看特征的名字\n",
    "tfidf.vocabulary_\n",
    "# 输出:\n",
    "# {'brazil': 3, 'country': 7, 'germany': 4, 'is': 5, 'best': 1, 'sweden': 6, 'both': 2, 'beats': 0}"
   ],
   "id": "62f114051aa6b10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "讨论：\n",
    "TF-IDF：词频-逆文档频率，衡量单词在文档中的重要性\n",
    "公式：tf-idf(t,d) = tf(t,d) × idf(t)\n",
    "tf(t,d)：词t在文档d中的频率\n",
    "idf(t)：log(文档总数 / 包含词t的文档数)\n",
    "特点：在多个文档中频繁出现的词（如停止词）权重降低"
   ],
   "id": "89597da10776b076"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "讨论：\n",
    "TF-IDF：词频-逆文档频率，衡量单词在文档中的重要性\n",
    "公式：tf-idf(t,d) = tf(t,d) × idf(t)\n",
    "tf(t,d)：词t在文档d中的频率\n",
    "idf(t)：log(文档总数 / 包含词t的文档数)\n",
    "特点：在多个文档中频繁出现的词（如停止词）权重降低\n",
    "知识点总结\n",
    "文本清洗：\n",
    "strip()：去除两端空格\n",
    "replace()：替换字符\n",
    "正则表达式：复杂模式匹配和替换\n",
    "BeautifulSoup：解析和清洗HTML\n",
    "文本预处理：\n",
    "分词：word_tokenize()（单词），sent_tokenize()（句子）\n",
    "停止词：使用NLTK的停止词表删除常见词\n",
    "词干提取：PorterStemmer将单词还原为词根\n",
    "词性标注：pos_tag()为单词标注词性（NNP, VBD, JJ等）\n",
    "文本向量化：\n",
    "词袋模型（Bag of Words）：CountVectorizer创建词频矩阵\n",
    "TF-IDF：TfidfVectorizer按单词重要性加权\n",
    "稀疏矩阵：默认输出，节省内存\n",
    "词汇表控制：通过vocabulary参数限制特征\n",
    "高级技巧：\n",
    "N-gram：设置ngram_range提取短语特征\n",
    "词性过滤：按词性标签筛选单词（如只保留名词）\n",
    "自定义转换：使用正则表达式和函数进行复杂清洗\n",
    "最佳实践：\n",
    "清洗步骤应包括：去空格、去标点、去HTML、分词、去停止词\n",
    "词干提取可统一不同形式的单词\n",
    "TF-IDF比简单词频更能反映单词重要性\n",
    "大规模文本使用稀疏矩阵存储"
   ],
   "id": "ec7955d78b32aeee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c209bee0a26eaf47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
